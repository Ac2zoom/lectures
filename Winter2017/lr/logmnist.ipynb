{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "with open('mnist01.pkl', 'rb') as f:\n",
    "    training, validation, test = pickle.load(f)\n",
    "    # fix a 1 on the end of each input vector to handle the bias\n",
    "    for dataset in (training, validation, test):\n",
    "        for idx in range(len(dataset)):\n",
    "            dataset[idx] = (np.append(dataset[idx][0], [1]), dataset[idx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_image(data):\n",
    "    from matplotlib import pyplot as plt\n",
    "    data = np.reshape(data[:-1], (28, 28))\n",
    "    plt.imshow(data, cmap='gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-44338.8496552\n",
      "-2706.76601872\n",
      "-1682.24386974\n",
      "-1355.17512008\n",
      "-1145.86073232\n",
      "-996.141271146\n",
      "-883.851610922\n",
      "-796.940621903\n",
      "-728.033314288\n",
      "-672.286566111\n",
      "-626.371006411\n",
      "-587.932981974\n",
      "-555.278529\n",
      "-527.170913734\n",
      "-502.694430735\n",
      "-481.161061213\n",
      "-462.046091902\n",
      "-444.943446014\n",
      "-429.534413934\n",
      "-415.565512512\n",
      "-402.832609727\n",
      "-391.169396445\n",
      "-380.438911303\n",
      "-370.527235936\n",
      "-361.338750813\n",
      "-352.792525384\n",
      "-344.819541168\n",
      "-337.360532552\n",
      "-330.364290199\n",
      "-323.786314366\n",
      "-317.587735485\n",
      "-311.734440957\n",
      "-306.196362627\n",
      "-300.946890662\n",
      "-295.962387852\n",
      "-291.221784343\n",
      "-286.706237379\n",
      "-282.398843986\n",
      "-278.284397076\n",
      "-274.349177431\n",
      "-270.580775475\n",
      "-266.967937974\n",
      "-263.500435668\n",
      "-260.168948572\n",
      "-256.964966265\n",
      "-253.880700961\n",
      "-250.909011468\n",
      "-248.043336519\n",
      "-245.277636152\n",
      "-242.606340048\n",
      "-240.024301874\n",
      "-237.526758861\n",
      "-235.109295913\n",
      "-232.767813695\n",
      "-230.498500175\n",
      "-228.29780521\n",
      "-226.162417799\n",
      "-224.089245688\n",
      "-222.075397042\n",
      "-220.11816395\n",
      "-218.215007559\n",
      "-216.363544642\n",
      "-214.561535439\n",
      "-212.806872661\n",
      "-211.097571485\n",
      "-209.431760477\n",
      "-207.807673318\n",
      "-206.223641271\n",
      "-204.678086294\n",
      "-203.169514747\n",
      "-201.696511634\n",
      "-200.257735318\n",
      "-198.851912672\n",
      "-197.477834623\n",
      "-196.13435205\n",
      "-194.820372003\n",
      "-193.534854216\n",
      "-192.276807883\n",
      "-191.045288679\n",
      "-189.839396001\n",
      "-188.658270405\n",
      "-187.501091239\n",
      "-186.367074428\n",
      "-185.255470429\n",
      "-184.165562312\n",
      "-183.096663984\n",
      "-182.048118523\n",
      "-181.01929663\n",
      "-180.009595165\n",
      "-179.018435801\n",
      "-178.045263744\n",
      "-177.089546536\n",
      "-176.150772943\n",
      "-175.228451892\n",
      "-174.32211149\n",
      "-173.431298088\n",
      "-172.555575407\n",
      "-171.694523706\n",
      "-170.847739012\n",
      "-170.014832378\n",
      "-169.195429191\n",
      "-168.389168513\n",
      "-167.595702466\n",
      "-166.81469564\n",
      "-166.045824542\n",
      "-165.288777063\n",
      "-164.543251989\n",
      "-163.808958514\n",
      "-163.085615806\n",
      "-162.372952572\n",
      "-161.670706657\n",
      "-160.978624659\n",
      "-160.29646156\n",
      "-159.623980387\n",
      "-158.960951873\n",
      "-158.307154151\n",
      "-157.662372445\n",
      "-157.026398796\n",
      "-156.39903178\n",
      "-155.780076258\n",
      "-155.169343123\n",
      "-154.56664907\n",
      "-153.971816368\n",
      "-153.384672647\n",
      "-152.805050693\n",
      "-152.232788257\n",
      "-151.667727864\n",
      "-151.109716635\n",
      "-150.558606121\n",
      "-150.014252138\n",
      "-149.47651461\n",
      "-148.945257425\n",
      "-148.420348289\n",
      "-147.901658588\n",
      "-147.389063265\n",
      "-146.88244069\n",
      "-146.381672541\n",
      "-145.886643691\n",
      "-145.397242098\n",
      "-144.9133587\n",
      "-144.434887314\n",
      "-143.961724541\n",
      "-143.493769669\n",
      "-143.030924593\n",
      "-142.573093718\n",
      "-142.120183889\n",
      "-141.672104303\n",
      "-141.228766438\n",
      "-140.790083982\n",
      "-140.355972758\n",
      "-139.926350665\n",
      "-139.501137603\n",
      "-139.080255423\n",
      "-138.663627856\n",
      "-138.251180466\n",
      "-137.842840587\n",
      "-137.438537274\n",
      "-137.038201251\n",
      "-136.64176486\n",
      "-136.249162018\n",
      "-135.860328165\n",
      "-135.475200225\n",
      "-135.093716562\n",
      "-134.715816937\n",
      "-134.341442473\n",
      "-133.970535609\n",
      "-133.603040073\n",
      "-133.238900839\n",
      "-132.878064094\n",
      "-132.520477207\n",
      "-132.166088696\n",
      "-131.814848196\n",
      "-131.466706428\n",
      "-131.121615175\n",
      "-130.779527246\n",
      "-130.440396457\n",
      "-130.104177598\n",
      "-129.770826414\n",
      "-129.440299573\n",
      "-129.112554647\n",
      "-128.78755009\n",
      "-128.465245212\n",
      "-128.145600157\n",
      "-127.828575886\n",
      "-127.514134154\n",
      "-127.202237488\n",
      "-126.892849175\n",
      "-126.585933232\n",
      "-126.2814544\n",
      "-125.97937812\n",
      "-125.679670515\n",
      "-125.382298376\n",
      "-125.087229145\n",
      "-124.794430903\n",
      "-124.503872347\n",
      "-124.215522782\n",
      "-123.929352106\n",
      "-123.64533079\n",
      "-123.363429874\n",
      "-123.083620947\n",
      "-122.805876135\n",
      "-122.530168091\n",
      "-122.256469981\n",
      "-121.984755473\n",
      "-121.714998726\n",
      "-121.447174377\n",
      "-121.181257532\n",
      "-120.917223754\n",
      "-120.655049053\n",
      "-120.394709879\n",
      "-120.136183107\n",
      "-119.879446031\n",
      "-119.624476353\n",
      "-119.371252177\n",
      "-119.119751996\n",
      "-118.869954685\n",
      "-118.621839496\n",
      "-118.375386043\n",
      "-118.130574302\n",
      "-117.887384595\n",
      "-117.645797589\n",
      "-117.405794288\n",
      "-117.16735602\n",
      "-116.930464438\n",
      "-116.695101506\n",
      "-116.461249498\n",
      "-116.228890988\n",
      "-115.998008844\n",
      "-115.768586224\n",
      "-115.540606568\n",
      "-115.314053591\n",
      "-115.088911281\n",
      "-114.86516389\n",
      "-114.642795929\n",
      "-114.421792166\n",
      "-114.202137614\n",
      "-113.983817532\n",
      "-113.766817419\n",
      "-113.551123007\n",
      "-113.336720256\n",
      "-113.123595351\n",
      "-112.911734699\n",
      "-112.701124921\n",
      "-112.491752849\n",
      "-112.283605523\n",
      "-112.076670184\n",
      "-111.870934273\n",
      "-111.666385427\n",
      "-111.463011472\n",
      "-111.260800422\n",
      "-111.059740473\n",
      "-110.859820003\n",
      "-110.661027564\n",
      "-110.463351884\n",
      "-110.266781857\n",
      "-110.071306545\n",
      "-109.876915172\n",
      "-109.683597122\n",
      "-109.491341936\n",
      "-109.300139308\n",
      "-109.109979083\n",
      "-108.920851254\n",
      "-108.732745958\n",
      "-108.545653474\n",
      "-108.359564223\n",
      "-108.174468759\n",
      "-107.990357773\n",
      "-107.807222087\n",
      "-107.62505265\n",
      "-107.443840542\n",
      "-107.263576963\n",
      "-107.084253239\n",
      "-106.905860812\n",
      "-106.728391243\n",
      "-106.551836211\n",
      "-106.376187505\n",
      "-106.201437025\n",
      "-106.027576782\n",
      "-105.854598894\n",
      "-105.682495584\n",
      "-105.511259176\n",
      "-105.340882099\n",
      "-105.171356879\n",
      "-105.002676141\n",
      "-104.834832606\n",
      "-104.667819089\n",
      "-104.501628497\n",
      "-104.336253829\n",
      "-104.171688173\n",
      "-104.007924706\n",
      "-103.844956689\n",
      "-103.682777469\n",
      "-103.521380476\n",
      "-103.360759223\n",
      "-103.200907303\n",
      "-103.041818386\n",
      "-102.883486222\n",
      "-102.725904637\n",
      "-102.569067531\n",
      "-102.412968879\n",
      "-102.257602728\n",
      "-102.102963197\n",
      "-101.949044473\n",
      "-101.795840815\n",
      "-101.643346548\n",
      "-101.491556063\n",
      "-101.340463818\n",
      "-101.190064336\n",
      "-101.040352202\n",
      "-100.891322064\n",
      "-100.742968631\n",
      "-100.595286674\n",
      "-100.448271021\n",
      "-100.301916561\n",
      "-100.156218239\n",
      "-100.011171057\n",
      "-99.8667700733\n",
      "-99.7230104002\n",
      "-99.5798872048\n",
      "-99.4373957071\n",
      "-99.2955311795\n",
      "-99.1542889462\n",
      "-99.0136643819\n",
      "-98.8736529115\n",
      "-98.734250009\n",
      "-98.5954511969\n",
      "-98.4572520458\n",
      "-98.3196481731\n",
      "-98.1826352425\n",
      "-98.0462089636\n",
      "-97.9103650907\n",
      "-97.7750994229\n",
      "-97.6404078026\n",
      "-97.5062861154\n",
      "-97.3727302896\n",
      "-97.2397362947\n",
      "-97.1073001423\n",
      "-96.9754178837\n",
      "-96.844085611\n",
      "-96.7132994556\n",
      "-96.5830555876\n",
      "-96.4533502159\n",
      "-96.324179587\n",
      "-96.195539985\n",
      "-96.0674277306\n",
      "-95.9398391807\n",
      "-95.8127707287\n",
      "-95.6862188026\n",
      "-95.5601798657\n",
      "-95.4346504156\n",
      "-95.3096269838\n",
      "-95.1851061354\n",
      "-95.0610844686\n",
      "-94.9375586141\n",
      "-94.8145252347\n",
      "-94.6919810253\n",
      "-94.5699227118\n",
      "-94.4483470514\n",
      "-94.3272508315\n",
      "-94.2066308699\n",
      "-94.0864840143\n",
      "-93.9668071413\n",
      "-93.8475971573\n",
      "-93.7288509966\n",
      "-93.6105656222\n",
      "-93.4927380251\n",
      "-93.3753652238\n",
      "-93.2584442642\n",
      "-93.1419722188\n",
      "-93.0259461869\n",
      "-92.9103632944\n",
      "-92.7952206926\n",
      "-92.6805155588\n",
      "-92.5662450955\n",
      "-92.4524065304\n",
      "-92.3389971156\n",
      "-92.2260141281\n",
      "-92.1134548686\n",
      "-92.0013166619\n",
      "-91.8895968563\n",
      "-91.7782928236\n",
      "-91.6674019583\n",
      "-91.5569216779\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-d81306cd5998>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m#print weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdlog_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-d81306cd5998>\u001b[0m in \u001b[0;36mlog_likelihood\u001b[1;34m(data, weights)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0msigm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msigm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msigm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-d81306cd5998>\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# write a function that takes in the training data and weights, and returns the gradient log likelihood of the data given the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# remember that σ(x) = e^x/(e^x+1)\n",
    "# each image is made up of 784 pixels, so we need to learn a 785x1 vector w that maximizes the likelihood\n",
    "# L(X,Y|w) = product_{i=1}^n p(y_i|x_i)\n",
    "# = product_{i=1}^n σ(x_i*w)^y_i*(1-σ(x_i*w))^(1-y_i)\n",
    "# we can get rid of the product by taking logs, and realizing that if we maximize the log, we're also maximizing\n",
    "# the original function.\n",
    "# LL(X,Y|w) = sum_{i=1}^n log(σ(x_i*w))*y_i + log(1-σ(x_i*w))*(1-y_i)\n",
    "# to maximize this, we'll use gradient descent!\n",
    "# the gradient of LL with respect to the weights is\n",
    "# d/dw LL(X,Y|w) = sum_{i=1}^n (y_i-σ(x_i*w))*x_i\n",
    "# (note that this is a vector!)\n",
    "\n",
    "# write the sigmoid function that takes in a real-valued x and returns σ(x) = e^x/(e^x+1)\n",
    "np.random.seed(0)\n",
    "def sigmoid(x):\n",
    "    return np.exp(x)/(np.exp(x)+1)\n",
    "\n",
    "# write a function that takes in the training data and weights, and returns the gradient log likelihood of the data given the weights\n",
    "\n",
    "def dlog_likelihood(data, weights):\n",
    "    total = 0\n",
    "    for x, y in data:\n",
    "        total += (y-sigmoid(np.dot(x, weights)))*x\n",
    "    return total\n",
    "\n",
    "# write a function that takes in the training data and weights, and returns the log likelihood (not the gradient)\n",
    "def log_likelihood(data, weights):\n",
    "    total = 0\n",
    "    for x, y in data:\n",
    "        sigm = sigmoid(np.dot(x, weights))\n",
    "        total += np.log(sigm)*y + np.log(1-sigm)*(1-y)\n",
    "        b = np.log(sigm)*y + np.log(1-sigm)*(1-y)\n",
    "    return total\n",
    "\n",
    "# let's initialize our weights to some random normal values (you can experiment with other initialization techniques)\n",
    "weights = np.random.randn(785)\n",
    "\n",
    "# set some \"learning rate\", which is how much the weights change in response to the gradient\n",
    "# if this is too low, learning will be slow. if it's too high, the behavior can be chaotic\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# for some number of iterations, repeatedly set weights = weights + learning_rate* d/dw LL(X,Y|weights)\n",
    "for i in range(1000):\n",
    "    #print weights\n",
    "    print log_likelihood(training, weights)\n",
    "    weights += learning_rate * dlog_likelihood(training, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2, 3]) * np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for x, y in training:\n",
    "    sigm = sigmoid(np.dot(weights,x))\n",
    "    if sigm > 0.5:\n",
    "        total += int(y==1)\n",
    "    else:\n",
    "        total += int(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10587"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (SageMath)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
